{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2>Projet Finance Quantitative</h2> </center> <br>\n",
    "<center> <h3>Master 2 MoSEF Data Science - Université Paris 1 Panthéon-Sorbonne</h3> </center> <br>\n",
    "<center> <h3><b>Genetic Algorithm-optimized Triple Barrier Labeling for Predictive Stock Trading Using GBM Stacking</b></h3> </center> <br>\n",
    "<center> <h3>Louis LEBRETON</h3> </center> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction des labels *buy*, *hold* et *sell*\n",
    "\n",
    "## Optimisation des modèles GBMs\n",
    "\n",
    "Dans un premier temps, j'optimise les modèles **XGBoost**, **LGBM**, et **CatBoost** sur un échantillon d'entraînement en utilisant une approche d'optimisation bayésienne. Cette méthode permet d'ajuster efficacement les hyperparamètres pour améliorer les performances des modèles.\n",
    "\n",
    "## Optimisation du classificateur Softmax\n",
    "\n",
    "Dans un second temps, j'optimise le métaclassificateur **Softmax** sur un échantillon de validation distinct afin d'éviter le surapprentissage (*overfitting*). Cette étape est également réalisée via une optimisation bayésienne.\n",
    "\n",
    "## Stratégies de trading\n",
    "\n",
    "Les données sont divisées en deux datasets distincts, chacun labellisé pour répondre à une stratégie de trading spécifique :\n",
    "\n",
    "1. **Stratégie High Risk, High Profit**  \n",
    "   - Objectif : Maximisation de 0.7 * profit - 0.3 * maximum drawdown.\n",
    "\n",
    "2. **Stratégie Low Risk, Low Profit**  \n",
    "   - Objectif : Maximisation de 0.3 * profit - 0.7 * maximum drawdown.\n",
    "\n",
    "## Évaluation des performances\n",
    "\n",
    "Une fois les modèles optimisés, j'évalue et compare les performances des prédictions en mesurant plusieurs métriques clés :  \n",
    "- **Profit**  \n",
    "- **Maximum drawdown**  \n",
    "- **Autres indicateurs pertinents**  \n",
    "\n",
    "\n",
    "## Période d'analyse\n",
    "\n",
    "Les données utilisées couvrent une période de cinq années, tout en excluant les impacts liés à la pandémie de COVID-19. Les années analysées sont les suivantes : **2018, 2019, 2022, 2023 et 2024**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, ParameterGrid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from prediction.GBM_stacking import GBMStacking\n",
    "\n",
    "from df_building.get_labels.equity_strategy import EquityStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_profile = 'HRHP' # or LRLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if risk_profile == 'HRHP':\n",
    "    risk_profile_type_dict = {'weight_p':0.7, 'weight_mdd':0.3} # High risk High profit\n",
    "else:\n",
    "    risk_profile_type_dict = {'weight_p':0.3, 'weight_mdd':0.7} # Low risk Low profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des données\n",
    "df_train = pd.read_csv(f\"../data/train_{risk_profile}.csv\", index_col=0)\n",
    "df_test = pd.read_csv(f\"../data/test_{risk_profile}.csv\", index_col=0)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.2, shuffle=True, random_state=1111)\n",
    "\n",
    "# renommage du label bail de -1 à 2 pour être compatible avec le modèle\n",
    "df_train[df_train['tbm label'] == -1]  = 2\n",
    "df_test[df_test['tbm label'] == -1]  = 2\n",
    "\n",
    "X_train, X_valid, X_test = df_train.drop(columns=['tbm label']), df_valid.drop(columns=['tbm label']), df_test.drop(columns=['tbm label'])\n",
    "y_train, y_valid, y_test = df_train['tbm label'].copy(), df_valid['tbm label'].copy(), df_test['tbm label'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédiction des labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation des GBMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation du XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, learning_rate, n_estimators, gamma, min_child_weight, subsample, colsample_bytree):\n",
    "    \"\"\"\n",
    "    evaluation d'un xgboost\n",
    "    \"\"\"\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    # modèle avec les hyperparamètres\n",
    "    model = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        gamma=gamma,\n",
    "        min_child_weight=min_child_weight,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        objective='multi:softprob',\n",
    "        num_class = num_classes,\n",
    "        random_state=111\n",
    "    )\n",
    "    \n",
    "    # cross val -> score\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.8061   \u001b[39m | \u001b[39m0.8453   \u001b[39m | \u001b[39m0.1365   \u001b[39m | \u001b[39m8.385    \u001b[39m | \u001b[39m3.658    \u001b[39m | \u001b[39m87.29    \u001b[39m | \u001b[39m0.5112   \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m2        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.7101   \u001b[39m | \u001b[39m1.193    \u001b[39m | \u001b[39m0.1079   \u001b[39m | \u001b[39m9.935    \u001b[39m | \u001b[39m3.14     \u001b[39m | \u001b[39m70.3     \u001b[39m | \u001b[39m0.8348   \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[39m3        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.8106   \u001b[39m | \u001b[39m1.371    \u001b[39m | \u001b[39m0.1452   \u001b[39m | \u001b[39m3.829    \u001b[39m | \u001b[39m1.666    \u001b[39m | \u001b[39m275.2    \u001b[39m | \u001b[39m0.897    \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.9203   \u001b[39m | \u001b[39m4.076    \u001b[39m | \u001b[39m0.2974   \u001b[39m | \u001b[39m7.041    \u001b[39m | \u001b[39m8.324    \u001b[39m | \u001b[39m155.3    \u001b[39m | \u001b[39m0.5137   \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39mnan      \u001b[39m | \u001b[39m0.7271   \u001b[39m | \u001b[39m0.5266   \u001b[39m | \u001b[39m0.247    \u001b[39m | \u001b[39m7.884    \u001b[39m | \u001b[39m6.088    \u001b[39m | \u001b[39m118.6    \u001b[39m | \u001b[39m0.9992   \u001b[39m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1000: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 139, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:334\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 334\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 20\u001b[0m\n\u001b[0;32m      1\u001b[0m param_bounds \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.3\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m      9\u001b[0m }\n\u001b[0;32m     12\u001b[0m xgb_optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(\n\u001b[0;32m     13\u001b[0m     f\u001b[38;5;241m=\u001b[39mxgb_evaluate,\n\u001b[0;32m     14\u001b[0m     pbounds\u001b[38;5;241m=\u001b[39mparam_bounds,\n\u001b[0;32m     15\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m111\u001b[39m,\n\u001b[0;32m     16\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m \u001b[43mxgb_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeilleurs hyperparamètres trouvés :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(xgb_optimizer\u001b[38;5;241m.\u001b[39mmax)\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:336\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter)\u001b[0m\n\u001b[0;32m    334\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:279\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mrandom_sample())\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Finding argmax of the acquisition function.\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m suggestion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquisition_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_gp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39marray_to_params(suggestion)\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\bayes_opt\\acquisition.py:414\u001b[0m, in \u001b[0;36mUpperConfidenceBound.suggest\u001b[1;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[0;32m    409\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived constraints, but acquisition function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support constrained optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConstraintNotSupportedError(msg)\n\u001b[1;32m--> 414\u001b[0m x_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_random\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_l_bfgs_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_l_bfgs_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_gp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_gp\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_exploration()\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_max\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\bayes_opt\\acquisition.py:127\u001b[0m, in \u001b[0;36mAcquisitionFunction.suggest\u001b[1;34m(self, gp, target_space, n_random, n_l_bfgs_b, fit_gp)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fit_gp:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_gp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m acq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_acq(gp\u001b[38;5;241m=\u001b[39mgp, constraint\u001b[38;5;241m=\u001b[39mtarget_space\u001b[38;5;241m.\u001b[39mconstraint)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acq_min(acq, target_space\u001b[38;5;241m.\u001b[39mbounds, n_random\u001b[38;5;241m=\u001b[39mn_random, n_l_bfgs_b\u001b[38;5;241m=\u001b[39mn_l_bfgs_b)\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\bayes_opt\\acquisition.py:81\u001b[0m, in \u001b[0;36mAcquisitionFunction._fit_gp\u001b[1;34m(self, gp, target_space)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m     80\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m     \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_space\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m         target_space\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(target_space\u001b[38;5;241m.\u001b[39mparams, target_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1318\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[1;32m-> 1318\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1328\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1328\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lebre\\OneDrive\\Bureau\\Finance Quant_S9\\Projet_QF\\Scripts\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "param_bounds = {\n",
    "    'max_depth': (3, 10),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'n_estimators': (50, 300),\n",
    "    'gamma': (0, 5),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "}\n",
    "\n",
    "\n",
    "xgb_optimizer = BayesianOptimization(\n",
    "    f=xgb_evaluate,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=111,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "\n",
    "xgb_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "print(\"meilleurs hyperparamètres trouvés :\")\n",
    "print(xgb_optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation du LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_evaluate(num_leaves, max_depth, learning_rate, n_estimators, min_child_weight, subsample, colsample_bytree):\n",
    "    \"\"\"\n",
    "    evaluation d'un lgbm\n",
    "    \"\"\"\n",
    "    num_leaves = int(num_leaves)\n",
    "    max_depth = int(max_depth)\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    # modèle avec les hyperparamètres\n",
    "    model = LGBMClassifier(\n",
    "        num_leaves=num_leaves,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        min_child_weight=min_child_weight,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        random_state=111\n",
    "    )\n",
    "    \n",
    "    # cross val -> score\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_param_bounds = {\n",
    "    'num_leaves': (20, 100),\n",
    "    'max_depth': (3, 15),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'n_estimators': (50, 300),\n",
    "    'min_child_weight': (1, 10),\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "}\n",
    "\n",
    "\n",
    "lgbm_optimizer = BayesianOptimization(\n",
    "    f=lgbm_evaluate,\n",
    "    pbounds=lgbm_param_bounds,\n",
    "    random_state=111,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "lgbm_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "\n",
    "print(\"meilleurs hyperparamètres lgbm trouvés :\")\n",
    "print(lgbm_optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation du Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_evaluate(depth, learning_rate, iterations, l2_leaf_reg, subsample):\n",
    "    \"\"\"\n",
    "    evaluation d'un catboost\n",
    "    \"\"\"\n",
    "  \n",
    "    depth = int(depth)\n",
    "    iterations = int(iterations)\n",
    "    \n",
    "    # modèle avec les hyperparamètres\n",
    "    model = CatBoostClassifier(\n",
    "        depth=depth,\n",
    "        learning_rate=learning_rate,\n",
    "        iterations=iterations,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        subsample=subsample,\n",
    "        loss_function='multi:softprob',\n",
    "        verbose=0,\n",
    "        random_state=111\n",
    "    )\n",
    "    \n",
    "    # cross val -> score\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_param_bounds = {\n",
    "    'depth': (3, 10),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'iterations': (50, 300),\n",
    "    'l2_leaf_reg': (1, 10),\n",
    "    'subsample': (0.5, 1),\n",
    "}\n",
    "\n",
    "catboost_optimizer = BayesianOptimization(\n",
    "    f=catboost_evaluate,\n",
    "    pbounds=catboost_param_bounds,\n",
    "    random_state=111,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "catboost_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "\n",
    "print(\"meilleurs hyperparamètres catboost trouvés :\")\n",
    "print(catboost_optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation du Metaclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaclassifier_evaluate(C, penalty, multi_class, solver):\n",
    "    \"\"\"\n",
    "    evaluation d'un catboost\n",
    "    \"\"\"\n",
    "  \n",
    "    depth = int(depth)\n",
    "    iterations = int(iterations)\n",
    "    \n",
    "    gbm_stacking_model = GBMStacking(models_to_use=('catboost', 'lightgbm', 'xgboost'),\n",
    "                                catboost_parameters=catboost_optimizer.max,\n",
    "                                lightgbm_parameters=lgbm_optimizer.max,\n",
    "                                xgboost_parameters=xgb_optimizer.max,\n",
    "                            logistic_regression_parameters={'C': C, \n",
    "                                                            'penalty': penalty, \n",
    "                                                            'multi_class': multi_class, \n",
    "                                                            'solver': solver})\n",
    "    gbm_stacking_model.fit(X_valid, y_valid)\n",
    "    predictions = gbm_stacking_model.predict(X_valid)\n",
    "\n",
    "    # cross val -> score\n",
    "    scores = cross_val_score(gbm_stacking_model, X_train, y_train, cv=3, scoring='roc_auc')\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaclassifier_param_bounds = {\n",
    "    'C': (0.01, 10),\n",
    "}\n",
    "\n",
    "metaclassifier_optimizer = BayesianOptimization(\n",
    "    f=metaclassifier_evaluate,\n",
    "    pbounds=metaclassifier_param_bounds,\n",
    "    random_state=111,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "metaclassifier_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "\n",
    "print(\"meilleurs hyperparamètres metaclassifier trouvés :\")\n",
    "print(metaclassifier_optimizer.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_stacking_model = GBMStacking(models_to_use=('catboost', 'lightgbm', 'xgboost'),\n",
    "                                catboost_parameters=catboost_optimizer.max,\n",
    "                                lightgbm_parameters=lgbm_optimizer.max,\n",
    "                                xgboost_parameters=xgb_optimizer.max,\n",
    "                            logistic_regression_parameters=metaclassifier_optimizer.max)\n",
    "gbm_stacking_model.fit(X_test, y_test)\n",
    "y_test_pred = gbm_stacking_model.predict(X_test)\n",
    "y_test_proba = gbm_stacking_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy : {accuracy:.2f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "print(f\"F1 Score : {f1:.2f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(\"rapport de classification :\")\n",
    "print(report)\n",
    "\n",
    "# auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binariser les labels pour une classification multi-classes\n",
    "classes = list(set(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "# Calculer l'AUC en mode one-vs-rest\n",
    "auc_score = roc_auc_score(y_test_bin, y_test_proba, average='weighted', multi_class='ovr')\n",
    "print(f\"AUC Score (multi-classes) : {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gbm_stacking_model, f\"../../data/models/gbm_stacking_model_{risk_profile}.pkl\")\n",
    "print(f\"modèle enregistré dans data/gbm_stacking_model_{risk_profile}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en place de la stratégie à partir des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"../../data/tbm_parameters_{risk_profile}.json\"\n",
    "\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    tbm_parameters = json.load(json_file)\n",
    "equity_strategy = EquityStrategy(df=df, buy_number=tbm_parameters['buy_number'], sell_number=tbm_parameters['sell_number'])\n",
    "profit = equity_strategy.calculate_profit()\n",
    "mdd = equity_strategy.calculate_maximum_drawdown()\n",
    "fitness = equity_strategy.fitness_function(weight_p=risk_profile_type_dict['weight_p'], weight_mdd=risk_profile_type_dict['weight_mdd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_curve = equity_strategy.equity_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplement hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_btc = df_price[0] / 100000\n",
    "# hold_equity_curve = nb_btc * df_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valeurs SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Création du dataframe X_test\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ROI extraction\u001b[39;00m\n\u001b[0;32m      6\u001b[0m fe \u001b[38;5;241m=\u001b[39m ROIsFeatureExtractor()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "\n",
    "# modèle\n",
    "final_model = gbm_stacking_model.named_steps['votingclassifier'].estimators_[0]\n",
    "\n",
    "# SHAP explainer\n",
    "explainer = shap.LinearExplainer(gbm_stacking_model, X_test)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 10 prédicteurs les plus importants\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=10)\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
